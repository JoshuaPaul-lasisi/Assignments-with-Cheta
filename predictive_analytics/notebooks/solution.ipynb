{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad56f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49946cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b745a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For time-series forecasting\n",
    "# Prophet (install with: pip install prophet)\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "    PROPHET_AVAILABLE = True\n",
    "except Exception:\n",
    "    PROPHET_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658aeb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LSTM\n",
    "try:\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "    from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "    KERAS_AVAILABLE = True\n",
    "except Exception:\n",
    "    KERAS_AVAILABLE = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbd5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afc2f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path='.../data/raw/superstore.csv'):\n",
    "    df = pd.read_csv(path, parse_dates=['order_date','ship_date'], low_memory=False)\n",
    "    # Basic type conversions\n",
    "    df['postal_code'] = df['postal_code'].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1681d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Basic cleaning & EDA helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cleaning(df):\n",
    "    # Drop rows with missing order_id or sales\n",
    "    df = df.dropna(subset=['order_id','sales'])\n",
    "    # Convert sales, profit, discount to numeric if needed\n",
    "    df['sales'] = pd.to_numeric(df['sales'], errors='coerce')\n",
    "    df['profit'] = pd.to_numeric(df['profit'], errors='coerce')\n",
    "    df['discount'] = pd.to_numeric(df['discount'], errors='coerce')\n",
    "    df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce')\n",
    "    # Fill simple NA\n",
    "    df['segment'] = df['segment'].fillna('Unknown')\n",
    "    df['region'] = df['region'].fillna('Unknown')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick EDA summary\n",
    "def eda_summary(df):\n",
    "    print('Rows:', len(df))\n",
    "    print('Date range:', df['order_date'].min(), '->', df['order_date'].max())\n",
    "    print(df[['sales','profit','discount','quantity']].describe())\n",
    "    print('\\nTop categories:')\n",
    "    print(df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd11fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Forecasting sales by category / sub_category / region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080be454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sales to monthly series per group\n",
    "def aggregate_monthly(df, group_cols=['category']):\n",
    "    df2 = df.copy()\n",
    "    df2['year_month'] = df2['order_date'].dt.to_period('M').dt.to_timestamp()\n",
    "    grouped = df2.groupby(group_cols + ['year_month']).agg({'sales':'sum'}).reset_index()\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eec0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a dataframe for Prophet: columns ds, y\n",
    "def prepare_prophet_df(grouped, group_values, group_cols=['category']):\n",
    "    # group_values: dict mapping col->value, e.g. {'category':'Furniture'}\n",
    "    g = grouped.copy()\n",
    "    for c,v in group_values.items():\n",
    "        g = g[g[c]==v]\n",
    "    g = g.sort_values('year_month')\n",
    "    prophet_df = g[['year_month','sales']].rename(columns={'year_month':'ds','sales':'y'})\n",
    "    prophet_df['ds'] = pd.to_datetime(prophet_df['ds'])\n",
    "    return prophet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast with Prophet\n",
    "def forecast_with_prophet(prophet_df, periods=12, freq='M'):\n",
    "    if not PROPHET_AVAILABLE:\n",
    "        raise RuntimeError('Prophet is not installed in your environment. Install prophet via pip.')\n",
    "    m = Prophet()\n",
    "    m.fit(prophet_df)\n",
    "    future = m.make_future_dataframe(periods=periods, freq=freq)\n",
    "    forecast = m.predict(future)\n",
    "    return m, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a034686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple ARIMA using statsmodels (auto_arima is not included; user can tune)\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "def forecast_with_arima(series, order=(1,1,1), steps=12):\n",
    "    # series: pd.Series indexed by datetime\n",
    "    model = ARIMA(series, order=order)\n",
    "    res = model.fit()\n",
    "    fc = res.get_forecast(steps=steps)\n",
    "    pred = fc.predicted_mean\n",
    "    conf = fc.conf_int()\n",
    "    return res, pred, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda689ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM pipeline (requires keras)\n",
    "def build_lstm_forecast(series, n_input=12, n_epochs=50, n_batch=16, n_neurons=50):\n",
    "    if not KERAS_AVAILABLE:\n",
    "        raise RuntimeError('Keras/TensorFlow is not available in this environment.')\n",
    "    # series: Pandas Series, index datetime, frequency monthly ideally\n",
    "    data = series.values.reshape(-1,1)\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    generator = TimeseriesGenerator(data_scaled, data_scaled, length=n_input, batch_size=n_batch)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_neurons, activation='tanh', input_shape=(n_input,1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(generator, epochs=n_epochs, verbose=1)\n",
    "    # Forecast next n_input steps iteratively\n",
    "    pred_scaled = []\n",
    "    current_batch = data_scaled[-n_input:].reshape((1,n_input,1))\n",
    "    for i in range(n_input):\n",
    "        pred = model.predict(current_batch)[0]\n",
    "        pred_scaled.append(pred)\n",
    "        current_batch = np.append(current_batch[:,1:,:], [[pred]], axis=1)\n",
    "    pred = scaler.inverse_transform(np.array(pred_scaled).reshape(-1,1)).flatten()\n",
    "    return model, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c800926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper to run forecasting for all groups and store results\n",
    "def run_category_forecasts(df, group_cols=['category'], periods=12):\n",
    "    grouped = aggregate_monthly(df, group_cols=group_cols)\n",
    "    forecasts = []\n",
    "    unique_groups = grouped[group_cols].drop_duplicates()\n",
    "    for _, row in unique_groups.iterrows():\n",
    "        group_values = {c: row[c] for c in group_cols}\n",
    "        prophet_df = prepare_prophet_df(grouped, group_values, group_cols=group_cols)\n",
    "        if len(prophet_df) < 12:\n",
    "            # skip small series\n",
    "            continue\n",
    "        try:\n",
    "            if PROPHET_AVAILABLE:\n",
    "                m, forecast = forecast_with_prophet(prophet_df, periods=periods)\n",
    "                fc = forecast[['ds','yhat']].tail(periods)\n",
    "                fc['group'] = str(group_values)\n",
    "                forecasts.append(fc)\n",
    "        except Exception as e:\n",
    "            print('Forecast failed for', group_values, e)\n",
    "    if forecasts:\n",
    "        return pd.concat(forecasts, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6f7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Customer churn modelling (RFM + classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a5912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rfm(df, snapshot_date=None):\n",
    "    # snapshot_date: date to compute recency relative to; default = max(order_date)+1 day\n",
    "    if snapshot_date is None:\n",
    "        snapshot_date = df['order_date'].max() + pd.Timedelta(days=1)\n",
    "    cust = df.groupby('customer_id').agg({\n",
    "        'order_date': lambda x: (snapshot_date - x.max()).days,\n",
    "        'order_id': 'nunique',\n",
    "        'sales': 'sum',\n",
    "        'quantity': 'sum',\n",
    "        'discount':'mean'\n",
    "    }).rename(columns={'order_date':'recency','order_id':'frequency','sales':'monetary','discount':'avg_discount','quantity':'total_qty'}).reset_index()\n",
    "    return cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label churn: customers with no orders in last N days\n",
    "def label_churn(df, churn_days=180):\n",
    "    snapshot_date = df['order_date'].max() + pd.Timedelta(days=1)\n",
    "    last_purchase = df.groupby('customer_id')['order_date'].max().reset_index()\n",
    "    last_purchase['days_since_last'] = (snapshot_date - last_purchase['order_date']).dt.days\n",
    "    last_purchase['churn_label'] = (last_purchase['days_since_last'] > churn_days).astype(int)\n",
    "    return last_purchase[['customer_id','churn_label','days_since_last']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ac63bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_profit_regression(df):\n",
    "    # We'll run an OLS regression: profit ~ discount + category + region + quantity + sales\n",
    "    # Create dummies for category and region\n",
    "    d = df.copy()\n",
    "    d = d.dropna(subset=['profit','discount'])\n",
    "    d['log_sales'] = np.log1p(d['sales'])\n",
    "    # Create dummies with limited cardinality\n",
    "    cat_dummies = pd.get_dummies(d['category'], prefix='cat', drop_first=True)\n",
    "    reg_dummies = pd.get_dummies(d['region'], prefix='reg', drop_first=True)\n",
    "    X = pd.concat([d[['discount','quantity','log_sales']], cat_dummies, reg_dummies], axis=1)\n",
    "    X = sm.add_constant(X)\n",
    "    y = d['profit']\n",
    "    model = sm.OLS(y, X).fit(cov_type='HC3')\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1fab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: run a simple grouped analysis to find discount thresholds where profit turns negative\n",
    "\n",
    "def discount_thresholds_by_category(df):\n",
    "    d = df.copy()\n",
    "    bins = [ -0.01, 0.0, 0.05, 0.1, 0.2, 0.5, 1.0]\n",
    "    d['disc_bin'] = pd.cut(d['discount'], bins=bins)\n",
    "    grouped = d.groupby(['category','disc_bin']).agg({'sales':'sum','profit':'sum','quantity':'sum','order_id':'nunique'}).reset_index()\n",
    "    grouped['profit_margin'] = grouped['profit'] / grouped['sales']\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee3f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Putting it all together - run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e79c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_pipeline(path='superstore.csv'):\n",
    "    df = load_data(path)\n",
    "    df = basic_cleaning(df)\n",
    "    eda_summary(df)\n",
    "\n",
    "    print('\\nRunning category forecasts (Prophet if available) - this may take time...')\n",
    "    cat_fc = run_category_forecasts(df, group_cols=['category'], periods=12)\n",
    "    print('Forecasts generated for categories:', cat_fc['group'].nunique() if not cat_fc.empty else 0)\n",
    "\n",
    "    print('\\nTraining churn model...')\n",
    "    churn_model = train_churn_model(df)\n",
    "\n",
    "    print('\\nRunning discount->profit regression...')\n",
    "    reg_model = discount_profit_regression(df)\n",
    "\n",
    "    print('\\nComputing discount thresholds per category...')\n",
    "    disc_summary = discount_thresholds_by_category(df)\n",
    "\n",
    "    return {\n",
    "        'data': df,\n",
    "        'category_forecasts': cat_fc,\n",
    "        'churn_model': churn_model,\n",
    "        'profit_regression': reg_model,\n",
    "        'discount_summary': disc_summary\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
